# üîß Troubleshooting - Problemas com Ollama

## Erro: "bind: Normalmente √© permitida apenas uma utiliza√ß√£o de cada endere√ßo de soquete (protocolo/endere√ßo de rede/porta)"

### O que significa?

Este erro acontece quando voc√™ tenta iniciar o Ollama, mas ele j√° est√° rodando em outro processo ou terminal.

A porta 11434 (porta padr√£o do Ollama) j√° est√° sendo usada por outra inst√¢ncia do Ollama.

---

## ‚úÖ Solu√ß√£o R√°pida (Mais Comum)

**Na maioria dos casos, o Ollama J√Å EST√Å RODANDO!**

### Verificar se est√° rodando:

```bash
ollama list
```

**Se funcionar** (mostrar a lista de modelos):
- ‚úÖ O Ollama j√° est√° rodando!
- ‚úÖ Voc√™ n√£o precisa fazer nada
- ‚úÖ Pode continuar usando normalmente

**Se n√£o funcionar** (erro de conex√£o):
- O Ollama n√£o est√° rodando
- Continue com as solu√ß√µes abaixo

---

## üîç Solu√ß√µes Detalhadas

### Solu√ß√£o 1: Encontrar e Parar o Processo Existente

#### Windows:

**Op√ß√£o A - Gerenciador de Tarefas:**
1. Pressione `Ctrl + Shift + Esc` para abrir o Gerenciador de Tarefas
2. V√° na aba "Processos" ou "Detalhes"
3. Procure por "ollama" ou "ollama.exe"
4. Clique com bot√£o direito > "Finalizar tarefa"
5. Confirme se necess√°rio

**Op√ß√£o B - Prompt de Comando:**
```cmd
# Encontrar o processo
netstat -ano | findstr :11434

# Voc√™ ver√° algo como:
# TCP    127.0.0.1:11434    0.0.0.0:0    LISTENING    12345
# O √∫ltimo n√∫mero (12345) √© o PID

# Parar o processo (substitua 12345 pelo PID que apareceu)
taskkill /PID 12345 /F
```

**Op√ß√£o C - PowerShell:**
```powershell
# Encontrar e parar
Get-Process -Name ollama -ErrorAction SilentlyContinue | Stop-Process -Force
```

#### Mac:

```bash
# Encontrar o processo
lsof -i :11434

# Voc√™ ver√° algo como:
# ollama  12345  usuario  ...  TCP localhost:11434 (LISTEN)
# O n√∫mero 12345 √© o PID

# Parar o processo
kill 12345

# Se n√£o funcionar, force:
kill -9 12345
```

#### Linux:

```bash
# Encontrar o processo
sudo lsof -i :11434
# ou
sudo netstat -tlnp | grep 11434
# ou
ps aux | grep ollama

# Parar o processo (substitua 12345 pelo PID)
kill 12345

# Se n√£o funcionar, force:
kill -9 12345
```

---

### Solu√ß√£o 2: Reiniciar o Ollama

Depois de parar o processo, inicie novamente:

```bash
ollama serve
```

**Importante:** Deixe este terminal aberto enquanto usar o FinGuia!

---

### Solu√ß√£o 3: Usar Outra Porta (Avan√ßado)

Se voc√™ realmente precisa rodar duas inst√¢ncias do Ollama:

1. **Inicie o Ollama em outra porta:**
   ```bash
   OLLAMA_HOST=127.0.0.1:11435 ollama serve
   ```

2. **Atualize o arquivo `.env`:**
   ```
   OLLAMA_BASE_URL=http://localhost:11435
   ```

3. **Reinicie os servi√ßos Docker:**
   ```bash
   docker-compose restart backend celery-worker
   ```

---

## üîÑ Verificar se Est√° Funcionando

### Teste 1: Listar modelos
```bash
ollama list
```
Deve mostrar seus modelos instalados (ex: `llama3.2`)

### Teste 2: Testar API
```bash
curl http://localhost:11434/api/tags
```
Deve retornar JSON com a lista de modelos

### Teste 3: Teste simples
```bash
ollama run llama3.2 "Ol√°, como voc√™ est√°?"
```
Deve responder (pode demorar alguns segundos)

---

## üê≥ Ollama com Docker

Se voc√™ est√° usando Docker e o Ollama est√° rodando localmente:

### Configura√ß√£o no `.env`:

**Windows:**
```
OLLAMA_BASE_URL=http://host.docker.internal:11434
```

**Mac/Linux:**
```
OLLAMA_BASE_URL=http://host.docker.internal:11434
# ou se n√£o funcionar:
OLLAMA_BASE_URL=http://172.17.0.1:11434
```

### Verificar se o Docker consegue acessar:

```bash
docker exec -it finguia-backend curl http://host.docker.internal:11434/api/tags
```

Se n√£o funcionar, tente:
```bash
# No Windows, adicione ao hosts (C:\Windows\System32\drivers\etc\hosts):
# 127.0.0.1 host.docker.internal
```

---

## üìã Checklist de Diagn√≥stico

Use este checklist para identificar o problema:

- [ ] O Ollama est√° instalado?
  ```bash
  ollama --version
  ```

- [ ] O modelo est√° instalado?
  ```bash
  ollama list
  ```

- [ ] O Ollama est√° rodando?
  ```bash
  ollama list
  # Se funcionar, est√° rodando
  ```

- [ ] A porta 11434 est√° livre?
  ```bash
  # Windows
  netstat -ano | findstr :11434
  
  # Mac/Linux
  lsof -i :11434
  ```

- [ ] O Docker consegue acessar o Ollama?
  ```bash
  docker exec -it finguia-backend curl http://host.docker.internal:11434/api/tags
  ```

- [ ] O arquivo `.env` est√° configurado corretamente?
  ```
  OLLAMA_BASE_URL=http://localhost:11434
  # ou
  OLLAMA_BASE_URL=http://host.docker.internal:11434
  ```

---

## üö® Problemas Comuns

### Problema: "Connection refused"

**Causa:** Ollama n√£o est√° rodando

**Solu√ß√£o:**
```bash
ollama serve
```

### Problema: "Model not found"

**Causa:** Modelo n√£o est√° instalado

**Solu√ß√£o:**
```bash
ollama pull llama3.2
```

### Problema: Docker n√£o consegue acessar Ollama local

**Causa:** Configura√ß√£o de rede

**Solu√ß√£o:**
1. Verifique o `.env`: `OLLAMA_BASE_URL=http://host.docker.internal:11434`
2. No Windows, pode precisar adicionar ao hosts
3. Tente usar o IP da m√°quina host diretamente

### Problema: Ollama muito lento

**Causa:** Modelo muito grande ou hardware insuficiente

**Solu√ß√£o:**
1. Use um modelo menor: `ollama pull llama3.2:1b` (vers√£o 1 bilh√£o de par√¢metros)
2. Feche outros programas pesados
3. Considere usar Ollama em servidor remoto mais potente

---

## üí° Dicas

1. **Deixe o Ollama rodando:** N√£o precisa fechar o terminal onde est√° rodando `ollama serve`

2. **Use um terminal separado:** Deixe o Ollama rodando em um terminal e use outro para o FinGuia

3. **Verifique antes de iniciar:** Sempre use `ollama list` para verificar se j√° est√° rodando

4. **Logs do Ollama:** Se tiver problemas, veja os logs no terminal onde est√° rodando `ollama serve`

5. **Reinicie se necess√°rio:** Se o Ollama travar, simplesmente pare (Ctrl+C) e inicie novamente

---

## üìû Ainda com Problemas?

Se nada funcionar:

1. **Reinstale o Ollama:**
   - Desinstale completamente
   - Baixe e instale novamente
   - Baixe o modelo novamente: `ollama pull llama3.2`

2. **Verifique firewall:**
   - Windows: Verifique se o Firewall n√£o est√° bloqueando
   - Mac: Verifique Prefer√™ncias do Sistema > Seguran√ßa

3. **Verifique permiss√µes:**
   - Certifique-se de ter permiss√µes para usar a porta 11434
   - No Linux, pode precisar de `sudo` (n√£o recomendado)

4. **Use Ollama em servidor remoto:**
   - Configure um servidor Ollama separado
   - Atualize `OLLAMA_BASE_URL` no `.env` com o IP do servidor

---

**Lembre-se:** Na maioria dos casos, o Ollama j√° est√° rodando e voc√™ s√≥ precisa verificar! ‚úÖ

